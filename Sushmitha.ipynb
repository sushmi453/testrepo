{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the useful libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import correlate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn import metrics\n",
    "#import statsmodels.api as sm\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "#import statsmodels\n",
    "#import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "# Libraries for text preprocessing and analysis\n",
    "import re,nltk,spacy,string\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "#from scipy.signal._signaltools import _centered\n",
    "from scipy.signal.signaltools import _centered\n",
    "# Libraries for model evaluation metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from statsmodels.compat.numpy import lstsq\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# row/column display limit\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset-  (30000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Movie Bundles &amp; Collections,CDs &amp; Vinyl,Rap &amp; Hip-Hop,Bass,Music on CD or Vinyl,Rap,Hip-Hop,Mainstream Rap,Pop Rap</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Cookies &amp; Chips,Rice Cakes,Cakes</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part of a promotion.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Cookies &amp; Chips,Rice Cakes,Cakes</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Spermicide,Health,Sexual Wellness,Lubricants</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before looking in to buying one of the couples lubricants, and was ultimately disappointed that it didn't even live up to the reviews I had read. For starters, neither my boyfriend nor I could notice any sort of enhanced or 'captivating' sensation. What we did notice, however, was the messy consistency that was reminiscent of a more liquid-y vaseline. It was difficult to clean up, and was not a pleasant, especially since it lacked the 'captivating' sensation we had both been expecting. I'm disappointed that I paid as much as I did for a lube that I won't use again, when I could just use their normal personal lubricant for 1) less money and 2) less mess.</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Spermicide,Health,Sexual Wellness,Lubricants</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel caused irritation and it felt like it was burning my skin. I wouldn't recommend this gel.</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                                                                                                                                       categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Movie Bundles & Collections,CDs & Vinyl,Rap & Hip-Hop,Bass,Music on CD or Vinyl,Rap,Hip-Hop,Mainstream Rap,Pop Rap   \n",
       "1                                                                                    Food,Packaged Foods,Snacks,Crackers,Snacks, Cookies & Chips,Rice Cakes,Cakes   \n",
       "2                                                                                    Food,Packaged Foods,Snacks,Crackers,Snacks, Cookies & Chips,Rice Cakes,Cakes   \n",
       "3                                                                           Personal Care,Medicine Cabinet,Lubricant/Spermicide,Health,Sexual Wellness,Lubricants   \n",
       "4                                                                           Personal Care,Medicine Cabinet,Lubricant/Spermicide,Health,Sexual Wellness,Lubricants   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               reviews_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Good flavor. This review was collected as part of a promotion.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Good flavor.   \n",
       "3  I read through the reviews on here before looking in to buying one of the couples lubricants, and was ultimately disappointed that it didn't even live up to the reviews I had read. For starters, neither my boyfriend nor I could notice any sort of enhanced or 'captivating' sensation. What we did notice, however, was the messy consistency that was reminiscent of a more liquid-y vaseline. It was difficult to clean up, and was not a pleasant, especially since it lacked the 'captivating' sensation we had both been expecting. I'm disappointed that I paid as much as I did for a lube that I won't use again, when I could just use their normal personal lubricant for 1) less money and 2) less mess.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      My husband bought this gel for us. The gel caused irritation and it felt like it was burning my skin. I wouldn't recommend this gel.   \n",
       "\n",
       "  reviews_title reviews_userCity reviews_userProvince reviews_username  \\\n",
       "0  Just Awesome      Los Angeles                  NaN           joshua   \n",
       "1          Good              NaN                  NaN        dorothy w   \n",
       "2          Good              NaN                  NaN        dorothy w   \n",
       "3  Disappointed              NaN                  NaN          rebecca   \n",
       "4    Irritation              NaN                  NaN        walker557   \n",
       "\n",
       "  user_sentiment  \n",
       "0       Positive  \n",
       "1       Positive  \n",
       "2       Positive  \n",
       "3       Negative  \n",
       "4       Negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review = pd.read_csv('sample30.csv')\n",
    "print('Shape of dataset- ',df_review.shape)\n",
    "df_review.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   id                    30000 non-null  object\n",
      " 1   brand                 30000 non-null  object\n",
      " 2   categories            30000 non-null  object\n",
      " 3   manufacturer          29859 non-null  object\n",
      " 4   name                  30000 non-null  object\n",
      " 5   reviews_date          29954 non-null  object\n",
      " 6   reviews_didPurchase   15932 non-null  object\n",
      " 7   reviews_doRecommend   27430 non-null  object\n",
      " 8   reviews_rating        30000 non-null  int64 \n",
      " 9   reviews_text          30000 non-null  object\n",
      " 10  reviews_title         29810 non-null  object\n",
      " 11  reviews_userCity      1929 non-null   object\n",
      " 12  reviews_userProvince  170 non-null    object\n",
      " 13  reviews_username      29937 non-null  object\n",
      " 14  user_sentiment        29999 non-null  object\n",
      "dtypes: int64(1), object(14)\n",
      "memory usage: 3.4+ MB\n",
      "['id' 'brand' 'categories' 'manufacturer' 'name' 'reviews_date'\n",
      " 'reviews_didPurchase' 'reviews_doRecommend' 'reviews_rating'\n",
      " 'reviews_text' 'reviews_title' 'reviews_userCity' 'reviews_userProvince'\n",
      " 'reviews_username' 'user_sentiment']\n"
     ]
    }
   ],
   "source": [
    "#print the information of dataframe to check their data types.\n",
    "df_review.info()\n",
    "print(df_review.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the shape of the Dataframe\n",
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.483133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.988441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviews_rating\n",
       "count    30000.000000\n",
       "mean         4.483133\n",
       "std          0.988441\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          5.000000\n",
       "75%          5.000000\n",
       "max          5.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe the data frame\n",
    "df_review.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of null values per column:\n",
      "reviews_userProvince    99.0\n",
      "reviews_userCity        94.0\n",
      "reviews_didPurchase     47.0\n",
      "reviews_doRecommend      9.0\n",
      "reviews_title            1.0\n",
      "user_sentiment           0.0\n",
      "reviews_username         0.0\n",
      "reviews_text             0.0\n",
      "reviews_rating           0.0\n",
      "reviews_date             0.0\n",
      "name                     0.0\n",
      "manufacturer             0.0\n",
      "categories               0.0\n",
      "brand                    0.0\n",
      "id                       0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find missing values/ % of null values percentage in the data set\n",
    "null_values_per_column = (100*round((df_review.isnull().sum())/len(df_review),2)).sort_values(ascending=False)\n",
    "print(\"% of null values per column:\")\n",
    "print(null_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new columns 'reviews' by merging the reviews_text and reviews_title columns\n",
    "df_review['reviews'] = df_review['reviews_title']+ \" \"+df_review['reviews_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the existing reviews_text and reviews_title columns\n",
    "df_review.drop(['reviews_text', 'reviews_title'], axis =1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df_review.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a clean dataframe\n",
    "df_clean_review = df_review[['name','reviews_username','reviews_rating','user_sentiment','reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>user_sentiment</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>joshua</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good Good flavor. This review was collected as part of a promotion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Good Good flavor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Disappointed I read through the reviews on here before looking in to buying one of the couples lubricants, and was ultimately disappointed that it didn't even live up to the reviews I had read. For starters, neither my boyfriend nor I could notice any sort of enhanced or 'captivating' sensation. What we did notice, however, was the messy consistency that was reminiscent of a more liquid-y vaseline. It was difficult to clean up, and was not a pleasant, especially since it lacked the 'captivating' sensation we had both been expecting. I'm disappointed that I paid as much as I did for a lube that I won't use again, when I could just use their normal personal lubricant for 1) less money and 2) less mess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>walker557</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Irritation My husband bought this gel for us. The gel caused irritation and it felt like it was burning my skin. I wouldn't recommend this gel.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name reviews_username  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)           joshua   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes        dorothy w   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes        dorothy w   \n",
       "3            K-Y Love Sensuality Pleasure Gel          rebecca   \n",
       "4            K-Y Love Sensuality Pleasure Gel        walker557   \n",
       "\n",
       "   reviews_rating user_sentiment  \\\n",
       "0               5       Positive   \n",
       "1               5       Positive   \n",
       "2               5       Positive   \n",
       "3               1       Negative   \n",
       "4               1       Negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 reviews  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Good Good flavor. This review was collected as part of a promotion.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Good Good flavor.  \n",
       "3  Disappointed I read through the reviews on here before looking in to buying one of the couples lubricants, and was ultimately disappointed that it didn't even live up to the reviews I had read. For starters, neither my boyfriend nor I could notice any sort of enhanced or 'captivating' sensation. What we did notice, however, was the messy consistency that was reminiscent of a more liquid-y vaseline. It was difficult to clean up, and was not a pleasant, especially since it lacked the 'captivating' sensation we had both been expecting. I'm disappointed that I paid as much as I did for a lube that I won't use again, when I could just use their normal personal lubricant for 1) less money and 2) less mess.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Irritation My husband bought this gel for us. The gel caused irritation and it felt like it was burning my skin. I wouldn't recommend this gel.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29996 entries, 0 to 29999\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   name              29996 non-null  object\n",
      " 1   reviews_username  29933 non-null  object\n",
      " 2   reviews_rating    29996 non-null  int64 \n",
      " 3   user_sentiment    29995 non-null  object\n",
      " 4   reviews           29810 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#ccheck the columns, non-null count, datatype of each column\n",
    "df_clean_review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29996, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.483131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.988456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviews_rating\n",
       "count    29996.000000\n",
       "mean         4.483131\n",
       "std          0.988456\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          5.000000\n",
       "75%          5.000000\n",
       "max          5.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe the data frame\n",
    "df_clean_review.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of null values per column:\n",
      "reviews             1.0\n",
      "user_sentiment      0.0\n",
      "reviews_rating      0.0\n",
      "reviews_username    0.0\n",
      "name                0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find missing values/ % of null values percentage in the data set\n",
    "null_values_per_column = (100*round((df_clean_review.isnull().sum())/len(df_review),2)).sort_values(ascending=False)\n",
    "print(\"% of null values per column:\")\n",
    "print(null_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_review.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map postivie sentiment as '1' and negative sentiment as '0'\n",
    "df_clean_review['user_sentiment']=df_clean_review['user_sentiment'].replace({'Positive' :1, \"Negative\" : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Typecasting from float to int datatype\n",
    "df_clean_review ['user_sentiment'] = df_clean_review['user_sentiment'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29747 entries, 0 to 29999\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   name              29747 non-null  object\n",
      " 1   reviews_username  29747 non-null  object\n",
      " 2   reviews_rating    29747 non-null  int64 \n",
      " 3   user_sentiment    29747 non-null  int64 \n",
      " 4   reviews           29747 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean_review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    20653\n",
       "4     5992\n",
       "1     1361\n",
       "3     1332\n",
       "2      409\n",
       "Name: reviews_rating, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_review.reviews_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                0\n",
       "reviews_username    0\n",
       "reviews_rating      0\n",
       "user_sentiment      0\n",
       "reviews             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_review.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Grapsh for the review_ratings Vs Length of the processed_reviews\n",
    "import seaborn as sns\n",
    "text_len = [len(text) for text in df_clean_review['reviews']]\n",
    "\n",
    "plt.figure(figsize=[12,6])\n",
    "sns.histplot(data=text_len,bins=20)\n",
    "plt.title('Distribution of Reviews Length', fontsize = 25)\n",
    "plt.xlabel('Reviews Text Length', size = 20)\n",
    "plt.ylabel('Number of Reviews',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\geddamsg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\geddamsg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\geddamsg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\geddamsg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Common functions for cleaning the text data \n",
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "import html\n",
    "\n",
    "# special_characters removal\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    \"\"\"Remove the special Characters\"\"\"\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation_and_splchars(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_word = remove_special_characters(new_word, True)\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "stopword_list= stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopword_list:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation_and_splchars(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def lemmatize(words):\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_lemmaize(input_text):\n",
    "    input_text = remove_special_characters(input_text)\n",
    "    words = nltk.word_tokenize(input_text)\n",
    "    words = normalize(words)\n",
    "    lemmas = lemmatize(words)\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for lemmatized review to the dataframe\n",
    "df_clean_review[\"final_review\"] =  df_clean_review.apply(lambda x: normalize_and_lemmaize(x['reviews']), axis=1)\n",
    "#final_review = lemmatized review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>user_sentiment</th>\n",
       "      <th>reviews</th>\n",
       "      <th>final_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>joshua</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.</td>\n",
       "      <td>awesome love album good hip hop side current pop sound hype listen everyday gym give star rat way metaphors crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Good Good flavor. This review was collected as part of a promotion.</td>\n",
       "      <td>good good flavor review collect part promotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Good Good flavor.</td>\n",
       "      <td>good good flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Disappointed I read through the reviews on here before looking in to buying one of the couples lubricants, and was ultimately disappointed that it didn't even live up to the reviews I had read. For starters, neither my boyfriend nor I could notice any sort of enhanced or 'captivating' sensation. What we did notice, however, was the messy consistency that was reminiscent of a more liquid-y vaseline. It was difficult to clean up, and was not a pleasant, especially since it lacked the 'captivating' sensation we had both been expecting. I'm disappointed that I paid as much as I did for a lube that I won't use again, when I could just use their normal personal lubricant for 1) less money and 2) less mess.</td>\n",
       "      <td>disappoint read review look buy one couple lubricants ultimately disappoint didnt even live review read starters neither boyfriend could notice sort enhance captivate sensation notice however messy consistency reminiscent liquidy vaseline difficult clean pleasant especially since lack captivate sensation expect im disappoint pay much lube wont use could use normal personal lubricant less money less mess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>walker557</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Irritation My husband bought this gel for us. The gel caused irritation and it felt like it was burning my skin. I wouldn't recommend this gel.</td>\n",
       "      <td>irritation husband buy gel us gel cause irritation felt like burn skin wouldnt recommend gel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name reviews_username  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)           joshua   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes        dorothy w   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes        dorothy w   \n",
       "3            K-Y Love Sensuality Pleasure Gel          rebecca   \n",
       "4            K-Y Love Sensuality Pleasure Gel        walker557   \n",
       "\n",
       "   reviews_rating  user_sentiment  \\\n",
       "0               5               1   \n",
       "1               5               1   \n",
       "2               5               1   \n",
       "3               1               0   \n",
       "4               1               0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 reviews  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Just Awesome i love this album. it's very good. more to the hip hop side than her current pop sound.. SO HYPE! i listen to this everyday at the gym! i give it 5star rating all the way. her metaphors are just crazy.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Good Good flavor. This review was collected as part of a promotion.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Good Good flavor.   \n",
       "3  Disappointed I read through the reviews on here before looking in to buying one of the couples lubricants, and was ultimately disappointed that it didn't even live up to the reviews I had read. For starters, neither my boyfriend nor I could notice any sort of enhanced or 'captivating' sensation. What we did notice, however, was the messy consistency that was reminiscent of a more liquid-y vaseline. It was difficult to clean up, and was not a pleasant, especially since it lacked the 'captivating' sensation we had both been expecting. I'm disappointed that I paid as much as I did for a lube that I won't use again, when I could just use their normal personal lubricant for 1) less money and 2) less mess.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Irritation My husband bought this gel for us. The gel caused irritation and it felt like it was burning my skin. I wouldn't recommend this gel.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                             final_review  \n",
       "0                                                                                                                                                                                                                                                                                                       awesome love album good hip hop side current pop sound hype listen everyday gym give star rat way metaphors crazy  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                          good good flavor review collect part promotion  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                        good good flavor  \n",
       "3  disappoint read review look buy one couple lubricants ultimately disappoint didnt even live review read starters neither boyfriend could notice sort enhance captivate sensation notice however messy consistency reminiscent liquidy vaseline difficult clean pleasant especially since lack captivate sensation expect im disappoint pay much lube wont use could use normal personal lubricant less money less mess  \n",
       "4                                                                                                                                                                                                                                                                                                                            irritation husband buy gel us gel cause irritation felt like burn skin wouldnt recommend gel  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19809\n",
       "0     2501\n",
       "Name: user_sentiment, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Test Divide\n",
    "x_train,x_test,y_train,y_test = train_test_split(df_clean_review['final_review'],df_clean_review['user_sentiment'],train_size=0.75,random_state=45,stratify=df_clean_review['user_sentiment'])\n",
    "y_train.value_counts()\n",
    "\n",
    "# review_new_df = df_clean_review in my sheet\n",
    "#lemmatized review = final_review in my sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22310, 15374)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "count_vect = CountVectorizer()\n",
    "x_count = count_vect.fit_transform(x_train)\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_train_transformed = tfidf_transformer.fit_transform(x_count)\n",
    "x_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creating the pickle for countvectorizer and TFIDF Transformer\n",
    "import pickle\n",
    "pickle.dump(count_vect,open(\"./Pickle/count_vector.pkl\",\"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf_transformer,open(\"./Pickle/tfidf_transformer.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling : Counter({1: 19809, 0: 2501})\n",
      "After sampling : Counter({1: 19809, 0: 19809})\n"
     ]
    }
   ],
   "source": [
    "count = Counter(y_train)\n",
    "print('Before sampling :',count)\n",
    "\n",
    "sampler = SMOTE()\n",
    "\n",
    "x_train_sm,y_train_sm = sampler.fit_resample(x_train_transformed,y_train)\n",
    "\n",
    "count = Counter(y_train_sm)\n",
    "print('After sampling :',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, string\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from plotly.offline import plot\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,roc_auc_score,confusion_matrix,f1_score,precision_score,accuracy_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Metrics\n",
    "performance=[]\n",
    "\n",
    "def model_metrics(y,y_pred,model_name,metrics):\n",
    "  Accuracy = accuracy_score(y,y_pred)\n",
    "  roc = roc_auc_score(y,y_pred)\n",
    "  confusion = confusion_matrix(y,y_pred)\n",
    "  precision = precision_score(y,y_pred)\n",
    "  f1 = f1_score(y,y_pred)\n",
    "  TP = confusion[1,1]  # true positive\n",
    "  TN = confusion[0,0]  # true negatives\n",
    "  FP = confusion[0,1]  # false positives\n",
    "  FN = confusion[1,0]  # false negatives\n",
    "  sensitivity= TP / float(TP+FN)\n",
    "  specificity = TN / float(TN+FP)\n",
    "\n",
    "  print(\"*\"*50)\n",
    "  print('Confusion Matrix =')\n",
    "  print(confusion)\n",
    "  print(\"sensitivity of the %s = %f\" % (model_name,round(sensitivity,2)))\n",
    "  print(\"specificity of the %s = %f\" % (model_name,round(specificity,2)))\n",
    "  print(\"Accuracy Score of %s = %f\" % (model_name,Accuracy))\n",
    "  print('ROC AUC score of %s = %f' % (model_name,roc))\n",
    "  print(\"Report=\",)\n",
    "  print(classification_report(y,y_pred))\n",
    "  print(\"*\"*50)\n",
    "  metrics.append(dict({'Model_name':model_name,\n",
    "                       'Accuracy':Accuracy,\n",
    "                       'Roc_auc_score':roc,\n",
    "                       'Precision':precision,\n",
    "                       'F1_score':f1}))\n",
    "  return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Logsitic Regression \n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(x_train_sm,y_train_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, string\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from plotly.offline import plot\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,roc_auc_score,confusion_matrix,f1_score,precision_score,accuracy_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[19042   767]\n",
      " [ 2014 17795]]\n",
      "sensitivity of the Logistic Regression = 0.900000\n",
      "specificity of the Logistic Regression = 0.960000\n",
      "Accuracy Score of Logistic Regression = 0.929805\n",
      "ROC AUC score of Logistic Regression = 0.929805\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93     19809\n",
      "           1       0.96      0.90      0.93     19809\n",
      "\n",
      "    accuracy                           0.93     39618\n",
      "   macro avg       0.93      0.93      0.93     39618\n",
      "weighted avg       0.93      0.93      0.93     39618\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(x_train_sm)\n",
    "peformance = model_metrics(y_train_sm,y_pred,'Logistic Regression',performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(lr,open(\"./Pickle/LogisticRegression.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. RandomForest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[19809     0]\n",
      " [    1 19808]]\n",
      "sensitivity of the RandomForestClassifier = 1.000000\n",
      "specificity of the RandomForestClassifier = 1.000000\n",
      "Accuracy Score of RandomForestClassifier = 0.999975\n",
      "ROC AUC score of RandomForestClassifier = 0.999975\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19809\n",
      "           1       1.00      1.00      1.00     19809\n",
      "\n",
      "    accuracy                           1.00     39618\n",
      "   macro avg       1.00      1.00      1.00     39618\n",
      "weighted avg       1.00      1.00      1.00     39618\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(x_train_sm)\n",
    "performance = model_metrics(y_train_sm,y_pred_rf,'RandomForestClassifier',performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost_AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[19809     0]\n",
      " [    1 19808]]\n",
      "sensitivity of the AdaBoostclassifier = 1.000000\n",
      "specificity of the AdaBoostclassifier = 1.000000\n",
      "Accuracy Score of AdaBoostclassifier = 0.999975\n",
      "ROC AUC score of AdaBoostclassifier = 0.999975\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19809\n",
      "           1       1.00      1.00      1.00     19809\n",
      "\n",
      "    accuracy                           1.00     39618\n",
      "   macro avg       1.00      1.00      1.00     39618\n",
      "weighted avg       1.00      1.00      1.00     39618\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "xgba = GradientBoostingClassifier()\n",
    "xgba.fit(x_train_sm,y_train_sm)\n",
    "y_pred_xgb = xgba.predict(x_train_sm)\n",
    "peformance = model_metrics(y_train_sm,y_pred_rf,'AdaBoostclassifier',peformance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[18870   939]\n",
      " [  933 18876]]\n",
      "sensitivity of the XGBClassifier = 0.950000\n",
      "specificity of the XGBClassifier = 0.950000\n",
      "Accuracy Score of XGBClassifier = 0.952749\n",
      "ROC AUC score of XGBClassifier = 0.952749\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     19809\n",
      "           1       0.95      0.95      0.95     19809\n",
      "\n",
      "    accuracy                           0.95     39618\n",
      "   macro avg       0.95      0.95      0.95     39618\n",
      "weighted avg       0.95      0.95      0.95     39618\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "#4.XGBoostClassifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(x_train_sm,y_train_sm)\n",
    "y_pred_xgbc = xgb_classifier.predict(x_train_sm)\n",
    "peformance = model_metrics(y_train_sm,y_pred_xgbc,'XGBClassifier',peformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[17694  2115]\n",
      " [ 2658 17151]]\n",
      "sensitivity of the NBClassifier_MultinomialNB = 0.870000\n",
      "specificity of the NBClassifier_MultinomialNB = 0.890000\n",
      "Accuracy Score of NBClassifier_MultinomialNB = 0.879524\n",
      "ROC AUC score of NBClassifier_MultinomialNB = 0.879524\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88     19809\n",
      "           1       0.89      0.87      0.88     19809\n",
      "\n",
      "    accuracy                           0.88     39618\n",
      "   macro avg       0.88      0.88      0.88     39618\n",
      "weighted avg       0.88      0.88      0.88     39618\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "#5.Naive Bayes\n",
    "#from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(x_train_sm,y_train_sm)\n",
    "y_pred_nbc = nb_classifier.predict(x_train_sm)\n",
    "peformance = model_metrics(y_train_sm,y_pred_nbc,'NBClassifier_MultinomialNB',peformance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc_auc_score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.929805</td>\n",
       "      <td>0.929805</td>\n",
       "      <td>0.958679</td>\n",
       "      <td>0.927523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostclassifier</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.952749</td>\n",
       "      <td>0.952749</td>\n",
       "      <td>0.952612</td>\n",
       "      <td>0.952756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBClassifier_MultinomialNB</td>\n",
       "      <td>0.879524</td>\n",
       "      <td>0.879524</td>\n",
       "      <td>0.890221</td>\n",
       "      <td>0.877850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model_name  Accuracy  Roc_auc_score  Precision  F1_score\n",
       "0         Logistic Regression  0.929805       0.929805   0.958679  0.927523\n",
       "1      RandomForestClassifier  0.999975       0.999975   1.000000  0.999975\n",
       "2          AdaBoostclassifier  0.999975       0.999975   1.000000  0.999975\n",
       "3               XGBClassifier  0.952749       0.952749   0.952612  0.952756\n",
       "4  NBClassifier_MultinomialNB  0.879524       0.879524   0.890221  0.877850"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(performance)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning of models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter tuning- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [200,400,600]\n",
    "max_depth = [6,10,15]\n",
    "min_samples_leaf = [5,6,8]\n",
    "criterion  = ['gini','entropy']\n",
    "params = {'n_estimators':n_estimators,\n",
    "          'max_depth':max_depth,\n",
    "          'min_samples_leaf': min_samples_leaf,\n",
    "          'criterion':criterion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params,\n",
    "                       n_jobs = -1,\n",
    "                       scoring = 'roc_auc',\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [6, 10, 15],\n",
       "                         'min_samples_leaf': [5, 6, 8],\n",
       "                         'n_estimators': [200, 400, 600]},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_leaf=5, n_estimators=600)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final=grid_cv.best_estimator_\n",
    "rf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_final,open(\"./Pickle/RandomForest_classifier.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9192707733570954"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[15615  4194]\n",
      " [ 1929 17880]]\n",
      "sensitivity of the RandomForestClassifier with hyperparmater = 0.900000\n",
      "specificity of the RandomForestClassifier with hyperparmater = 0.790000\n",
      "Accuracy Score of RandomForestClassifier with hyperparmater = 0.845449\n",
      "ROC AUC score of RandomForestClassifier with hyperparmater = 0.845449\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84     19809\n",
      "           1       0.81      0.90      0.85     19809\n",
      "\n",
      "    accuracy                           0.85     39618\n",
      "   macro avg       0.85      0.85      0.84     39618\n",
      "weighted avg       0.85      0.85      0.84     39618\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "y_pred_rfgcv = rf_final.predict(x_train_sm)\n",
    "performance = model_metrics(y_train_sm,y_pred_rfgcv,'RandomForestClassifier with hyperparmater',performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter tuning of XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [200,400,600]\n",
    "params_1 = {'n_estimators':n_estimators} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_boost = GridSearchCV(estimator=xgba,\n",
    "                       param_grid=params_1,\n",
    "                       n_jobs = -1,\n",
    "                       scoring = 'roc_auc',\n",
    "                       verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best score for GradientBoosting= 0.9720628549538801\n"
     ]
    }
   ],
   "source": [
    "grid_cv_boost.fit(x_train_sm,y_train_sm)\n",
    "print('Best score for GradientBoosting=',grid_cv_boost.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=600)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final=grid_cv_boost.best_estimator_\n",
    "xgb_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[18971   838]\n",
      " [ 1605 18204]]\n",
      "sensitivity of the GradientBoostClassifier with n = 600 = 0.920000\n",
      "specificity of the GradientBoostClassifier with n = 600 = 0.960000\n",
      "Accuracy Score of GradientBoostClassifier with n = 600 = 0.938336\n",
      "ROC AUC score of GradientBoostClassifier with n = 600 = 0.938336\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     19809\n",
      "           1       0.96      0.92      0.94     19809\n",
      "\n",
      "    accuracy                           0.94     39618\n",
      "   macro avg       0.94      0.94      0.94     39618\n",
      "weighted avg       0.94      0.94      0.94     39618\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgbgcv = xgb_final.predict(x_train_sm)\n",
    "peformance = model_metrics(y_train_sm,y_pred_xgbgcv,'GradientBoostClassifier with n = 600',peformance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc_auc_score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.929805</td>\n",
       "      <td>0.929805</td>\n",
       "      <td>0.958679</td>\n",
       "      <td>0.927523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostclassifier</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.952749</td>\n",
       "      <td>0.952749</td>\n",
       "      <td>0.952612</td>\n",
       "      <td>0.952756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBClassifier_MultinomialNB</td>\n",
       "      <td>0.879524</td>\n",
       "      <td>0.879524</td>\n",
       "      <td>0.890221</td>\n",
       "      <td>0.877850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier with hyperparmater</td>\n",
       "      <td>0.845449</td>\n",
       "      <td>0.845449</td>\n",
       "      <td>0.810003</td>\n",
       "      <td>0.853807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostClassifier with n = 600</td>\n",
       "      <td>0.938336</td>\n",
       "      <td>0.938336</td>\n",
       "      <td>0.955992</td>\n",
       "      <td>0.937119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model_name  Accuracy  Roc_auc_score  \\\n",
       "0                        Logistic Regression  0.929805       0.929805   \n",
       "1                     RandomForestClassifier  0.999975       0.999975   \n",
       "2                         AdaBoostclassifier  0.999975       0.999975   \n",
       "3                              XGBClassifier  0.952749       0.952749   \n",
       "4                 NBClassifier_MultinomialNB  0.879524       0.879524   \n",
       "5  RandomForestClassifier with hyperparmater  0.845449       0.845449   \n",
       "6       GradientBoostClassifier with n = 600  0.938336       0.938336   \n",
       "\n",
       "   Precision  F1_score  \n",
       "0   0.958679  0.927523  \n",
       "1   1.000000  0.999975  \n",
       "2   1.000000  0.999975  \n",
       "3   0.952612  0.952756  \n",
       "4   0.890221  0.877850  \n",
       "5   0.810003  0.853807  \n",
       "6   0.955992  0.937119  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(performance)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After doing multiple tuning we get the below model and will be used in the sentiment based analysis\n",
    "final_model = RandomForestClassifier(max_depth=15, min_samples_leaf=5, n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_leaf=5, n_estimators=400)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf_final,open(\"./Pickle/RandomForest_classifier.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation between LR,RF,NB, XGboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[ 637  197]\n",
      " [ 811 5792]]\n",
      "sensitivity of the Logistic Regression = 0.880000\n",
      "specificity of the Logistic Regression = 0.760000\n",
      "Accuracy Score of Logistic Regression = 0.864461\n",
      "ROC AUC score of Logistic Regression = 0.820483\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.76      0.56       834\n",
      "           1       0.97      0.88      0.92      6603\n",
      "\n",
      "    accuracy                           0.86      7437\n",
      "   macro avg       0.70      0.82      0.74      7437\n",
      "weighted avg       0.91      0.86      0.88      7437\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[ 483  351]\n",
      " [ 467 6136]]\n",
      "sensitivity of the XGBoost Classifier = 0.930000\n",
      "specificity of the XGBoost Classifier = 0.580000\n",
      "Accuracy Score of XGBoost Classifier = 0.890009\n",
      "ROC AUC score of XGBoost Classifier = 0.754206\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.58      0.54       834\n",
      "           1       0.95      0.93      0.94      6603\n",
      "\n",
      "    accuracy                           0.89      7437\n",
      "   macro avg       0.73      0.75      0.74      7437\n",
      "weighted avg       0.90      0.89      0.89      7437\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[17694  2115]\n",
      " [ 2658 17151]]\n",
      "sensitivity of the NBClassifier_MultinomialNB = 0.870000\n",
      "specificity of the NBClassifier_MultinomialNB = 0.890000\n",
      "Accuracy Score of NBClassifier_MultinomialNB = 0.879524\n",
      "ROC AUC score of NBClassifier_MultinomialNB = 0.879524\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88     19809\n",
      "           1       0.89      0.87      0.88     19809\n",
      "\n",
      "    accuracy                           0.88     39618\n",
      "   macro avg       0.88      0.88      0.88     39618\n",
      "weighted avg       0.88      0.88      0.88     39618\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[ 406  428]\n",
      " [ 675 5928]]\n",
      "sensitivity of the Tuned RandomForestClassifier = 0.900000\n",
      "specificity of the Tuned RandomForestClassifier = 0.490000\n",
      "Accuracy Score of Tuned RandomForestClassifier = 0.851688\n",
      "ROC AUC score of Tuned RandomForestClassifier = 0.692292\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.49      0.42       834\n",
      "           1       0.93      0.90      0.91      6603\n",
      "\n",
      "    accuracy                           0.85      7437\n",
      "   macro avg       0.65      0.69      0.67      7437\n",
      "weighted avg       0.87      0.85      0.86      7437\n",
      "\n",
      "**************************************************\n",
      "**************************************************\n",
      "Confusion Matrix =\n",
      "[[ 408  426]\n",
      " [ 713 5890]]\n",
      "sensitivity of the Tuned GradientBoostClassifier = 0.890000\n",
      "specificity of the Tuned GradientBoostClassifier = 0.490000\n",
      "Accuracy Score of Tuned GradientBoostClassifier = 0.846847\n",
      "ROC AUC score of Tuned GradientBoostClassifier = 0.690614\n",
      "Report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.49      0.42       834\n",
      "           1       0.93      0.89      0.91      6603\n",
      "\n",
      "    accuracy                           0.85      7437\n",
      "   macro avg       0.65      0.69      0.66      7437\n",
      "weighted avg       0.87      0.85      0.86      7437\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "#Evaluation between lr , rf and boost \n",
    "test_performance=[]\n",
    "test_word_vect = count_vect.transform(x_test)\n",
    "test_tfidf_vect = tfidf_transformer.transform(test_word_vect)\n",
    "\n",
    "y_test_pred_lr = lr.predict(test_tfidf_vect)\n",
    "test_peformance = model_metrics(y_test,y_test_pred_lr,'Logistic Regression',test_performance)\n",
    "\n",
    "y_test_pred_xgbc = xgb_classifier.predict(test_tfidf_vect)\n",
    "test_peformance = model_metrics(y_test,y_test_pred_xgbc,'XGBoost Classifier',test_performance)\n",
    "\n",
    "y_test_pred_nbc = final_model.predict(test_tfidf_vect)\n",
    "peformance = model_metrics(y_train_sm,y_pred_nbc,'NBClassifier_MultinomialNB',test_peformance)\n",
    "\n",
    "y_test_pred_rf = rf_final.predict(test_tfidf_vect)\n",
    "test_peformance = model_metrics(y_test,y_test_pred_rf,'Tuned RandomForestClassifier',test_performance)\n",
    "\n",
    "y_test_pred_xgb = final_model.predict(test_tfidf_vect)\n",
    "test_peformance = model_metrics(y_test,y_test_pred_xgb,'Tuned GradientBoostClassifier',test_performance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc_auc_score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.864461</td>\n",
       "      <td>0.820483</td>\n",
       "      <td>0.967106</td>\n",
       "      <td>0.919949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.890009</td>\n",
       "      <td>0.754206</td>\n",
       "      <td>0.945892</td>\n",
       "      <td>0.937510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBClassifier_MultinomialNB</td>\n",
       "      <td>0.879524</td>\n",
       "      <td>0.879524</td>\n",
       "      <td>0.890221</td>\n",
       "      <td>0.877850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned RandomForestClassifier</td>\n",
       "      <td>0.851688</td>\n",
       "      <td>0.692292</td>\n",
       "      <td>0.932662</td>\n",
       "      <td>0.914885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned GradientBoostClassifier</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.690614</td>\n",
       "      <td>0.932552</td>\n",
       "      <td>0.911835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model_name  Accuracy  Roc_auc_score  Precision  F1_score\n",
       "0            Logistic Regression  0.864461       0.820483   0.967106  0.919949\n",
       "1             XGBoost Classifier  0.890009       0.754206   0.945892  0.937510\n",
       "2     NBClassifier_MultinomialNB  0.879524       0.879524   0.890221  0.877850\n",
       "3   Tuned RandomForestClassifier  0.851688       0.692292   0.932662  0.914885\n",
       "4  Tuned GradientBoostClassifier  0.846847       0.690614   0.932552  0.911835"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics_df = pd.DataFrame(test_performance)\n",
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with test data after comparing \n",
    "- After Hyperparameter Tuning Considering roc_auc_score ,performance, Naive Bayes is having more score and have good accuracy. This will be our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final model - Naive Bayes nto pickle file\n",
    "import pickle\n",
    "NB = MultinomialNB()\n",
    "pickle.dump(NB,open(\"./Pickle/model.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Recommedation system\n",
    "- User and User recommedation system \n",
    "- Item and Item recommedation system "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User and User recommedation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample30.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape =  (21000, 15)\n",
      "test shape =  (9000, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(df,train_size=0.70,random_state=45)\n",
    "print('train shape = ',train.shape)\n",
    "print('test shape = ',test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using train dataset and create correlation matrix \n",
    "train_pivot = pd.pivot_table(index='reviews_username',\n",
    "                            columns='name',\n",
    "                            values='reviews_rating',data=train).fillna(1)\n",
    "train_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the train and test dataset for predicting and evaluating the correlation\n",
    "#fill 1 in place of Nan for prediction \n",
    "train_pivot1 = pd.pivot_table(index='reviews_username',\n",
    "                            columns='name',\n",
    "                            values='reviews_rating',data=train).fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pivot1.loc['piggyboy420']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are going use the adjusted cosine similarity \n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(df):\n",
    "    # using the adjusted cosine similarity \n",
    "    mean_df = np.nanmean(df,axis=1)\n",
    "    substracted_df = (df.T - mean_df).T # Normalized dataset\n",
    "    # using the pairwise_distance for cosine similarity \n",
    "    user_correlation = 1- pairwise_distances (substracted_df.fillna(0),metric='cosine')\n",
    "    user_correlation[np.isnan(user_correlation)] = 0\n",
    "    return user_correlation,substracted_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "user_corr_matrix,normalized_df = cosine_similarity(train_pivot1)\n",
    "user_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIv0ASr7zLLs",
    "outputId": "a7b99cfa-5b2e-4b1c-9222-5f37f235c24b"
   },
   "outputs": [],
   "source": [
    "user_corr_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eL5_ky7kzLLt",
    "outputId": "c6455953-af81-4410-b8f3-0f02d92a8b45"
   },
   "outputs": [],
   "source": [
    "user_corr_matrix[user_corr_matrix < 0] = 0\n",
    "user_corr_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "id": "FXRWk8QpzLLt",
    "outputId": "873f4290-1220-413e-d20d-13ebb52af276"
   },
   "outputs": [],
   "source": [
    "df[df['reviews_username'] == 'zzz1127']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pred_ratings = np.dot(user_corr_matrix,train_pivot1.fillna(0))\n",
    "user_pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pred_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_final_rating = np.multiply(user_pred_ratings,train_pivot)\n",
    "user_final_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading User-User Recommendation System in Pickle file user_final_rating.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pickle file for user-user recommendation system\n",
    "import pickle \n",
    "pickle.dump(user_final_rating,open('./Pickle/user_final_rating.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top20 Product Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = user_final_rating\n",
    "d.loc['piggyboy420'].sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxBEFB9ozLLu"
   },
   "source": [
    "### Evaluation for user-user recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "common = test[test.reviews_username.isin(train.reviews_username)]\n",
    "common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame(user_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df['user_name'] = normalized_df.index\n",
    "corr_df.set_index('user_name',inplace=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name = common.reviews_username.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.columns = normalized_df.index.tolist()\n",
    "corr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df1 = corr_df[corr_df.index.isin(list_name)]\n",
    "corr_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df2 = corr_df1.T[corr_df1.T.index.isin(list_name)]\n",
    "corr_df3 = corr_df2.T\n",
    "corr_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_tb = pd.pivot_table(index='reviews_username',\n",
    "                            columns='name',\n",
    "                            values='reviews_rating',data=common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df3[corr_df3<0] = 0\n",
    "common_user_rating =  np.dot(corr_df3,common_user_tb.fillna(0))\n",
    "common_user_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test = common.copy()\n",
    "dummy_test['reviews_rating'] =dummy_test['reviews_rating'].apply(lambda x: 1 if x>=1 else 0)\n",
    "dummy_test = pd.pivot_table(index='reviews_username',\n",
    "                            columns='name',\n",
    "                            values='reviews_rating',data=dummy_test).fillna(0)\n",
    "dummy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_user_pred_ratings =  np.multiply(common_user_rating,dummy_test)\n",
    "common_user_pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import *\n",
    "\n",
    "X  = common_user_pred_ratings.copy() \n",
    "X = X[X>0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "print(scaler.fit(X))\n",
    "y = (scaler.transform(X))\n",
    "\n",
    "print(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total non-NaN value\n",
    "total_non_nan = np.count_nonzero(~np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_non_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pivot = pd.pivot_table(index='reviews_username',\n",
    "                            columns='name',\n",
    "                            values='reviews_rating',data=common)\n",
    "common_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (sum(sum((common_pivot -  y )**2))/total_non_nan)**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ym4IEkm1zLLx"
   },
   "source": [
    "## Item and Item recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "IoDSJsWozLLx",
    "outputId": "6c396646-3179-4af0-c3f2-f3788c896446"
   },
   "outputs": [],
   "source": [
    "train_pivot_ii = train_pivot1.T\n",
    "train_pivot_ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_corr_matrix, normalized_item_df = cosine_similarity(train_pivot_ii)\n",
    "item_corr_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pred_rating = np.dot((train_pivot_ii.fillna(0)).T,item_corr_matrix)\n",
    "item_pred_rating[item_pred_rating<0] = 0\n",
    "item_pred_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final rating for items\n",
    "item_final_rating = np.multiply(item_pred_rating,train_pivot)\n",
    "item_final_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_item = item_final_rating\n",
    "d_item.loc['piggyboy420'].sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the train dataset into dummy_train\n",
    "dummy_train = train.copy()\n",
    "dummy_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Item and Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_item = test[test.name.isin(train.name)]\n",
    "common_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_item_pivot = common_item.pivot_table(index='reviews_username',\n",
    "                            columns='name',\n",
    "                            values='reviews_rating').T\n",
    "\n",
    "common_item_pivot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_corr_df = pd.DataFrame(item_corr_matrix)\n",
    "item_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_corr_df['name'] = normalized_item_df.index\n",
    "item_corr_df.set_index('name',inplace=True)\n",
    "item_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_items = common_item.name.tolist()\n",
    "item_corr_df.columns = normalized_item_df.index.tolist()\n",
    "item_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_corr_df1 = item_corr_df[item_corr_df.index.isin(list_items)]\n",
    "item_corr_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_corr_df2 = item_corr_df1.T[item_corr_df1.T.index.isin(list_items)]\n",
    "item_corr_df3 = item_corr_df2.T\n",
    "item_corr_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_corr_df3[item_corr_df3<0] = 0\n",
    "common_item_pred_ratings = np.dot(item_corr_df3,common_item_pivot.fillna(0))\n",
    "common_item_pred_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = common_item.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_item_tb = test_items.pivot_table(index='reviews_username',\n",
    "                            columns='name',\n",
    "                            values='reviews_rating').T.fillna(0)\n",
    "final_item_ratings = np.multiply(common_item_pred_ratings,test_item_tb)\n",
    "final_item_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = final_item_ratings.copy() \n",
    "X = X[X>0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "print(scaler.fit(X))\n",
    "y = (scaler.transform(X))\n",
    "\n",
    "print(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total non-NaN value\n",
    "total_non_nan = np.count_nonzero(~np.isnan(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (sum(sum((common_item_pivot -  y )**2))/total_non_nan)**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rmse,open(\"./Pickle/rmse.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aVfcF4EzLL0"
   },
   "source": [
    "<font color=Blue> \n",
    "    \n",
    "#### <u> SUMMARY:</u>  \n",
    "    \n",
    "1. RMSE for USER-USER is 1.87 and RMSE for ITEM-ITEM is 3.55. Lesser the RMSE better the model. Hence User-User \n",
    "recommendation system is suitable recommendataion systems for this dataset\n",
    "2. User-User Recommedation is loaded into available in user_final_rating.pkl\n",
    "</font>\n",
    "\n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=Blue> \n",
    "    \n",
    "#### <u> Notes:</u>  \n",
    "    \n",
    "1. Model.py: This file has the Top 20 Products and Top 5 Products recommended based on sentiment\n",
    "2. Pickle files: Are avaialble in Pickle folder\n",
    "3. Heroku URL : \n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
